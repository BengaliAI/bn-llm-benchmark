dataset,avg_tokens_per_word,avg_bytes_per_token,avg_normalized_seq_len
arc-challenge-bn,6.6403494804367735,2.49041256490061,0.8726693206510496
arc-challenge-en,1.300964813731512,4.732854760017065,0.994802261658134
arc-easy-bn,6.664951815531119,2.4911327095448854,0.8719646261191714
arc-easy-en,1.3091945205659739,4.7452219323509235,0.9924124272799231
boolq-bn,7.127091177332338,2.5212562077793685,0.8746610383725253
boolq-en,1.3415016370902724,4.735344820786077,1.0152498515448023
commonsenseqa-bn,6.481983976758591,2.4762747150321736,0.8734950747849491
commonsenseqa-en,1.3644534398792216,4.512958660628703,0.9906690850205765
gsm8k-main-bn,6.851840665823797,2.4551794822677073,0.8832354953168114
gsm8k-main-en,1.4010983588810821,4.651396092835527,1.0315757218527073
hellaswag-bn,6.483196522897711,2.4958376835200156,0.8792645173017115
hellaswag-en,1.260438490100763,4.601700205291793,0.9975490236493425
mmlu-bn,6.752119510079855,2.4919296306445906,0.8751498692028364
mmlu-en,1.3401479405236678,4.688179564611837,1.0032792259051184
openbookqa-bn,6.5266680599567435,2.4888912918816373,0.8684435060507205
openbookqa-en,1.3175424943180396,4.660076033120553,0.9904210740239948
piqa-bn,6.650587782909505,2.5084675513376364,0.8748212535036305
piqa-en,1.24863622575973,4.85631500372787,0.9921109667564142
winogrande-bn,6.677659924219535,2.5239520050128896,0.8722202305379627
winogrande-en,1.2422834865376982,5.037823519685927,0.9885702030017275
