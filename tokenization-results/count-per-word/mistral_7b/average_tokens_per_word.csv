dataset,avg_tokens_per_word,avg_bytes_per_token,avg_normalized_seq_len
arc-challenge-bn,7.009255089808878,2.359510432920814,0.9213007889439733
arc-challenge-en,1.4476600495903489,4.254963217957911,1.1068374491994912
arc-easy-bn,7.033709809400333,2.360641716160812,0.920334609541752
arc-easy-en,1.460516947603287,4.256391675480218,1.1068397334882047
boolq-bn,7.457786592795012,2.4099400438683696,0.915351060680562
boolq-en,1.4880968223097355,4.2693539232657765,1.126021417119628
commonsenseqa-bn,6.867279300705856,2.337436550896501,0.9254825197642871
commonsenseqa-en,1.5108340234232962,4.07682854465237,1.0968490402877384
gsm8k-main-bn,7.381079601137099,2.279339696929592,0.9514978510459231
gsm8k-main-en,1.4962961900960114,4.35646968713836,1.1015996509646198
hellaswag-bn,6.7239619501299766,2.406849300140544,0.9119560918554629
hellaswag-en,1.3874729428750496,4.1817650071045955,1.0980057384726203
mmlu-bn,7.083369795154883,2.3755157508479665,0.9182503903143296
mmlu-en,1.493390692412127,4.206463071865699,1.1179714510340428
openbookqa-bn,6.872226445551623,2.3638738347521993,0.9144959166503522
openbookqa-en,1.4571683725261448,4.21543989733477,1.0951636003849867
piqa-bn,6.909505706518212,2.4145768047233664,0.9089959287338018
piqa-en,1.3983468507305716,4.338772827158188,1.1108613610947837
winogrande-bn,7.004731367242997,2.406162845391181,0.9150148225446507
winogrande-en,1.3935582554292398,4.493067160005741,1.1088487470040287
